# Generates synthetic statutes
import  random
import re

from generate_utils import TYPE_LEAF, TYPE_DEFINITIONS, TYPE_APPLIES_TO, definition_re, get_num_tokens

class statute_part:
    def __init__(self, term:str):
        self.term = term  # e.g. "vilihick" -- the term being referenced
        self.parent = None # None for root, otherwise reference
        self.children = None # starts out as none; add later using function below
        self.stat_used = None # e.g. 1001(a)(3)(A)
        self.stat_defined = None # e.g. 1001(a)(3)(A)(iii)
        self.sentence_num = None # int.  useful for creating numbered prose sentences.

    def add_child(self, new_child):
        if new_child is None:
            return
        if self.children is None:
            self.children = []
        for c in self.children:
            assert c.term != new_child.term
        self.children.append(new_child)
        new_child.parent = self

    def has_children(self):
        return self.children is not None and len(self.children) > 0

    def has_grandchildren(self):
        return self.has_children() and self.children[0].has_children()

    def get_all_descendants(self) -> list:
        rv = [self]
        if self.has_children():
            for c in self.children:
                rv.extend(c.get_all_descendants())
        return rv

    def print_statute_info_recursive(self):
        used = "--"
        if not self.stat_used is None:
            used = self.stat_used
        defined = "--"
        if not self.stat_defined is None:
            defined = self.stat_defined

        print("{0:<25s} {1:<25s}".format(used, defined), self.term)
        if not self.children is None:
            for child in self.children:
                child.print_statute_info_recursive()

    def print_statute_info(self):
        print("{0:<25s} {1:<25s}".format("stat_used", "stat_defined"))
        self.print_statute_info_recursive()

    def get_level(self):
        if self.parent is None:
            return 0
        else:
            return 1 + self.parent.get_level()

    # gets distance, in tree edges, from x
    def get_dist(self, x):
        self_walker = self
        self_count = 0
        while self_walker is not None:
            x_walker = x
            x_count = 0
            while x_walker is not None:
                if self_walker == x_walker:
                    return self_count + x_count
                x_walker = x_walker.parent
                x_count += 1
            self_walker = self_walker.parent
            self_count += 1
        assert False, "Got two that are not in the same tree"

    # Find the item in the other_statute that is in the exact same position
    # as self.  The assumption is that the source statute for self is
    # different from other_statute; otherwise, it just returns self.
    def get_analogous_item(self, other_statute):
        tree_branches = []
        x = self
        while x.parent is not None:
            tree_branches.append(x.parent.children.index(x))
            x = x.parent
        y = other_statute
        while len(tree_branches) > 0:
            y = y.children[tree_branches.pop()]
        return y

    def get_root(self):
        x = self
        while x.parent is not None:
            x = x.parent
        return x

# This generates the abstract representation of the synthetic statute.
def generate_abstract(stack_names:list, tree_depth:int, branch_factor:int, cur_depth=0):
    if cur_depth > tree_depth:
        return None
    if cur_depth == 0:
        rv = statute_part("") # assign name later when giving None for parent
    else:
        rv = statute_part(stack_names.pop())

    for i in range(branch_factor):
        rv.add_child(generate_abstract(stack_names, tree_depth, branch_factor, cur_depth+1))
    if cur_depth == 0:
        rv.term = stack_names.pop()
        assert rv. parent is None

    return rv

# Extracts a list of all terms that appear as the first item the 2-tuples in the tree
# generated by generate_abstract().
def extract_all_used_terms(abst) -> list:
    rv = [abst.term.lower()] # we want lower case versions
    if abst.has_children():
        for child in abst.children:
            rv.extend(extract_all_used_terms(child))
    return rv

# Extracts a list of all terms that appear as the first item the 2-tuples in the tree
# generated by generate_abstract().
def extract_all_used_parts(abst) -> list:
    rv = [abst] # we want lower case versions
    if abst.has_children():
        for child in abst.children:
            rv.extend(extract_all_used_parts(child))
    return rv

# Reads from a file filled with nonces generated by https://www.soybomb.com/tricks/words/
def read_nonces() -> list:
    with open("../RawData/synthetic_nonces.txt", "r") as f:
        nonce_txt = f.read()
    lowercase_nonce_list = nonce_txt.split()
    # verify none are duplicated, which would cause statutory problems
    rv = []

    duplicates = []
    for nonce in lowercase_nonce_list:
        candidate = nonce[0].upper() + nonce[1:].lower()
        if candidate[-1:] == "s": # remove ending s, which indicates plural and might confuse language models
            candidate = candidate[:-1]
        assert candidate.isalpha()
        if candidate not in rv: # no duplicates!
            # make sure there is no overlap of part of one term over another
            overlap = False
            for already_in in rv:
                if candidate.lower() in already_in.lower() or \
                   already_in.lower() in candidate.lower():
                    overlap = True
            if not overlap:
                rv.append(candidate)

    for x in rv:
        for y in rv:
            if x != y:
                assert not x.lower() in y.lower()
    print("Number of nonces =", len(rv))
    return rv

# This generates a set of names like "M11" and "Z66"
def generate_systematic() -> list:
    rv = []
    for idx_letter in range(26):
        for idx_num in range(10):
            rv.append(chr(ord('A')+idx_letter) + str(idx_num) + str(idx_num))
    return rv

# This generates a set of names like "AM41" and "ZQ60"
# def generate_ids() -> list:
#     rv = []
#     for letter1 in range(26):
#         for letter2 in range(26):
#             for num1 in range(10):
#                 for num2 in range(10):
#                     rv.append(chr(ord('A')+letter1) + chr(ord('A')+letter2) + str(num1) + str(num2))
#     return rv

# This generates a set of names like "AM414" and "ZQ602"
# This huge list will not be the default.  Rather, it will be appended at the end.
def generate_backup_ids() -> list:
    rv = []
    for letter1 in range(26):
        for letter2 in range(26):
            for num1 in range(10):
                for num2 in range(10):
                    for num3 in range(10):
                        rv.append(chr(ord('A')+letter1) + chr(ord('A')+letter2) + str(num1) + str(num2) + str(num3))
    return rv


# Used to generate roman numerals, which are used for clause and subclause numbering
def int_to_roman(num):
    if 1 <= num <= 3:
        return "i" * num
    elif num == 4:
        return "iv"
    elif 5 <= num <= 8:
        return "v" + ("i" * (num-5))
    elif num == 9:
        return "ix"
    elif 10 <= num <= 13:
        return "x" + ("i" * (num-10))
    elif num == 14:
        return "xiv"
    elif 15 <= num <= 18:
        return "xv" + ("i" * (num-15))
    else:
        assert False, "not implemented"

def level_num_label(level:int, num:int):
    rv = "  " * level + "("
    if level == 0: # subsection   (a)
        rv += (chr(ord('a') + (num%26)) * (1 + int(num/26)))
    elif level == 1: # paragraph  (1)
        rv += str(num+1)
    elif level == 2: # subparagraph (A)
        rv += (chr(ord('A') + (num%26)) * (1 + int(num/26)))
    elif level == 3: # clause (i)
        rv += int_to_roman(num+1).lower()
    elif level == 4: # subclause (I)
        rv += int_to_roman(num+1).upper()
    elif level == 5: # item (aa), (bb), (cc), etc.  See 5 USC sec. 1212 for examples
        rv += chr(ord('a') + num)
        rv += chr(ord('a') + num)
    elif level == 6: # subitem (AA), (BB), (CC), etc.   See 5 USC sec. 1212 for examples
        rv += chr(ord('A') + num)
        rv += chr(ord('A') + num)
    elif level == 7:  # subsubitem (aaa), (bbb), etc.   See 8 USC sec. 1154 for examples
        rv += chr(ord('a') + num)
        rv += chr(ord('a') + num)
        rv += chr(ord('a') + num)
    else:
        assert False, "not implemented"
    assert re.fullmatch("\s*[a-zA-Z0-9)(]*\s*", rv)
    return rv + ")"

# Creates appropriate separator between parts of a statute.
def sep(index, len_list) -> str:
    if index == len_list - 2:
        return ", or\n"
    elif index == len_list - 1:
        return ".\n"
    else:
        return ",\n"

def simple_sep(index, len_list) -> str:
    if index == len_list - 2:
        if len_list == 2:
            return " or"
        else:
            return ", or"
    elif index == len_list - 1:
        return "."
    else:
        return ","

CITE_FORMAT = "[{:40s}]"

# Takes an abstract representation and creates a statute (recursively).
# Also fills in the citation.
# collapse_leaves -- makes all leaf terms appear in a single line with their parent
def abstract_to_statute(abst,
                        level = 0,
                        context = None,
                        sec_num = 1001,
                        collapse_leaves=False) -> str:
    rv = ""
    if level == 0:
        context = "section " + str(sec_num)
        rv  = CITE_FORMAT.format(context) + \
              "Section " + str(sec_num) + ".  Definition of " + abst.term.lower() +".\n"
    if not abst.has_grandchildren(): # simple; definition in terms of leaf nodes
        if not collapse_leaves:
            rv += "The term \"" + abst.term.lower() + "\" means-\n"
            abst.stat_defined = context # store where it is defined
            for i, child in enumerate(abst.children):
                used_label = level_num_label(level, i)
                child.stat_used = context.strip() + used_label.strip() # store where it is used
                rv += CITE_FORMAT.format(child.stat_used) + used_label + " any " + child.term.lower() + sep(i, len(abst.children))
        else: # if here, we are collapsing the children into a single sentence on one line
            rv += "The term \"" + abst.term.lower() + "\" means"
            abst.stat_defined = context # store where it is defined
            for i, child in enumerate(abst.children):
                used_label = level_num_label(level, i)
                child.stat_used = context.strip() + used_label.strip() # store where it is used
                rv += " any " + child.term.lower() + simple_sep(i, len(abst.children)) # no newline
            rv += "\n"
    else:
        def_label = level_num_label(level, 0)
        rv += CITE_FORMAT.format(context.strip()+def_label.strip()) + def_label + " General rule"
        rv += ". "
        if not collapse_leaves:
            rv += "The term \"" + abst.term.lower() + "\" means-\n"
            abst.stat_defined = context.strip()
            for i, child in enumerate(abst.children):
                used_label = level_num_label(level + 1, i)
                child.stat_used = abst.stat_defined.strip() + def_label.strip() + used_label.strip()
                rv += CITE_FORMAT.format(child.stat_used) + used_label + " any " + child.term.lower() + sep(i, len(abst.children))
        else:
            rv += "The term \"" + abst.term.lower() + "\" means"
            abst.stat_defined = context.strip()
            for i, child in enumerate(abst.children):
                used_label = level_num_label(level + 1, i)
                rv += " any " + child.term.lower() + simple_sep(i, len(abst.children))
                child.stat_used = abst.stat_defined.strip() + def_label.strip() + used_label.strip()
            rv += "\n"

        for i, child in enumerate(abst.children):
            head_label = level_num_label(level, i+1)
            rv += CITE_FORMAT.format(context.strip()+head_label.strip()) + head_label
            if collapse_leaves:
                if child.has_grandchildren():
                    rv += " Definition of " + child.term.lower() + "\n"
                else:
                    rv += " "
            else:
                if child.has_grandchildren():
                    rv += " Definition of " + child.term.lower()
                    rv += "\n"
                else:
                    rv += " "

            rv += abstract_to_statute(child,
                                      level + 1,
                                      context.strip() + head_label.strip(),
                                      collapse_leaves=collapse_leaves)
    return rv

# For most words, this will be "a".  But for words starting with
# a vowel or some abbreviations, it will be "an"
def get_article(word):
    if word[0].isalpha() and word[-1].isalpha():
        if word[0].lower() in "aeiou":
            return "an"
    elif word[0].isalpha() and word[-1].isnumeric():
        if word[0].lower() in "aefhilmnorsx":
            # an A-plus, an E-class, an F-U, an H14, an I9, an L4, an M16, an N99, an O-ring, an R5, an S22, an X-ray
            return "an"
    else:
        assert False, "not implemented"
    return "a" # the default

# This function derives the ground truth against which we measure accuracy.  It's important.
# Returns True if it definitely applies.
# Returns False if it definitely does NOT apply
# Returns *None* if may or may not apply -- so shouldn't test
# To understand reasoning, consider statute "(i) foo means (I) any bar or (II) any boo"
def does_A_apply_to_anyB(A, B):
    if A == B:
        if not A.has_children():
            # if Alice is a boo, then (i)(II) definitely applies to Alice
            return True
        else:
            # If Alice is a foo, then does (i) above apply to Alice?
            # It's Unclear, since Alice was a foo even without (i).  So return None since ambiguous.
            return None

    # if A is a parent, grandparent, etc. of B,  it definitely applies
    # For example, if A is (i) and B is boo.
    x = B
    while not x is None:
        if x == A:
            assert A != B or not A.has_children()
            return True
        x = x.parent
    # if sentence can be used to construct the part, then arguably applies
    y = A
    while not y is None:
        if y == B:
            # If Alice is a foo, then does (I) above apply to Alice?
            # Unclear, so we return None in that circumstance.
            return None
        y = y.parent
    return False

# We need to use random names with equal change of each gender to avoid bias.
# The below were drawn from the top 15 baby names each at https://www.ssa.gov/oact/babynames/decades/names2000s.html.
FEMALE_NAMES = ["Emily", "Madison", "Emma", "Olivia","Hannah","Abigail","Isabella","Samantha",
            "Elizabeth","Ashley","Alexis","Sarah","Sophia","Alyssa","Grace"  ]
MALE_NAMES = ["Jacob", "Michael", "Joshua", "Matthew", "Daniel", "Christopher", "Andrew",
         "Ethan", "Joseph", "William", "Anthony", "David", "Alexander", "Nicholas", "Ryan"]
NAMES = MALE_NAMES.copy()
NAMES.extend(FEMALE_NAMES) # merge

# returns a list of dicts
def generate_items(rand_seed:int,
                   widthdepth:str,
                   num:int,
                   filter_type:str,
                   synthetic_nouns:str) -> list:
    rv = []
    rand_gen = random.Random(rand_seed)

    # we need to parse the widthdepth into a list of (width,depth) 2-tuples
    widthdepth_list = []
    for wd in widthdepth.split(";"):
        assert len(wd.split(",")) == 2, \
            "Incorrect format? Expect semi-colon deliminated list of number-comma-number like 4,3"
        width = int(wd.split(",")[0].strip())
        depth = int(wd.split(",")[1].strip())
        widthdepth_list.append((width,depth))

    if synthetic_nouns == "nonces":
        raw_nonce_list = read_nonces()
    elif synthetic_nouns == "ids":
        raw_nonce_list = generate_systematic() # called IDs in Blair-Stanek et al. 2023
    else:
        assert False, "Not implemented"

    # raw_backup_nonce_list = generate_backup_ids() # can be used if we run out of nonces or ids
    for idx in range(num):
        # nonce_list = raw_backup_nonce_list.copy()
        # rand_gen.shuffle(nonce_list)
        nonce_list = []
        primary_list = raw_nonce_list.copy()
        rand_gen.shuffle(primary_list)
        nonce_list.extend(primary_list) # pop() will first use this list

        # choose the relevant size from the possibilities, with each being uniformly
        width, depth = widthdepth_list[idx % len(widthdepth_list)]

        collapse_leaves = (filter_type == TYPE_DEFINITIONS)


        # Generate the statute
        before_nonce_len = len(nonce_list)
        abst = generate_abstract(nonce_list, depth, width)
        after_nonce_len = len(nonce_list)
        if idx < len(widthdepth_list):
            print("width {:2d} depth {:2d} used {:5d} nonces".format(width,
                                                                     depth,
                                                                     before_nonce_len-after_nonce_len),
                  # "from {:4d} to {:4d}".format(before_nonce_len, after_nonce_len),
                  end=" ")

        section_num = rand_gen.randint(1010, 9999)
        stat_str = abstract_to_statute(abst, sec_num=section_num, collapse_leaves=collapse_leaves)

        # Now separate into the relevant list of dicts, plus the actual statute
        full_text = ""
        text_lines = []
        for line in stat_str.split("\n"):
            if len(line) > 0:
                cite = line.split("]")[0].strip("[").strip()
                line_text = line.split("]")[1]
                full_text += line_text + "\n"
                text_lines.append({"cite": cite, "line_text": line_text})
        full_text = full_text.strip()

        # Now we need to randomly choose a line
        if filter_type==TYPE_LEAF:
            possible_line_indices = \
                [i for i, d in enumerate(text_lines) if d["cite"].count("(") == depth]
            idx_line = rand_gen.choice(possible_line_indices)
            rv.append({"full_text": full_text,
                       "text_lines": text_lines,
                       "idx_line": idx_line,
                       "width": width,
                       "depth": depth})
        elif filter_type == TYPE_DEFINITIONS:
            # For definitions, we avoid the first two lines
            possible_line_indices = []
            for i, line in enumerate(text_lines):
                matches = definition_re.findall(line["line_text"])
                line["defined_terms"] = matches # store all the defined terms
                if (len(matches) == 1 and i > 1):
                    possible_line_indices.append(i)
            idx_line = rand_gen.choice(possible_line_indices)
            rv.append({"full_text": full_text,
                       "text_lines": text_lines,
                       "idx_line": idx_line,
                       "width": width,
                       "depth": depth})
        elif filter_type == TYPE_APPLIES_TO:
            all_parts = extract_all_used_parts(abst)

            # Per Blair-Stanek et al (2023), The subsection "is randomly
            # chosen, although it is never a leaf".
            possible_target_subsection = \
                [p for p in all_parts if p.has_children() and not p.parent is None]
            target_subsection = rand_gen.choice(possible_target_subsection)

            # Then we also have to choose the type that the person is.
            # Per Blair-Stanek et al. (2023):  "We balance all tests with equal
            # numbers having positive groundtruth (e.g. section 1001(b) is not
            # applicable) and negative groundtruth (e.g. section 1001(b) is applicable)."
            # Here, we implement this balance with even ones being True and odd ones being False
            applies_value = (0 == (idx % 2))
            possible_person_types = \
                [p for p in all_parts if applies_value == does_A_apply_to_anyB(target_subsection, p)]
            person_type = rand_gen.choice(possible_person_types)

            person_name = rand_gen.choice(NAMES) # choose a name

            question = person_name + " is " + get_article(person_type.term) + \
                " " + person_type.term.lower() + ". Is " + \
                       target_subsection.stat_defined + " applicable to " + person_name + \
                       "? " + \
                       "Let's think step by step."
                       # "Carefully read and apply the section above step-by-step, being certain to spell out your " + \
                       # "reasoning in painstaking detail. Write at least 200 words of reasoning."
                       # # "Carefully read and apply the section above, being certain to spell out your " + \
                       # # "reasoning so anyone can verify them. Spell out everything in painstaking " + \
                       # # "detail and don't skip any steps!  Use as much space as you need."

            rv.append({"full_text": full_text,
                       "text_lines": text_lines,
                       "question": question,
                       "answer": applies_value,
                       "width": width,
                       "depth": depth})
        else:
            assert False
        if idx < len(widthdepth_list):
            print("tokens= {:7d}".format(get_num_tokens(rv[-1]["full_text"])))


    return rv

if __name__ == "__main__":
    stats = generate_items(42, "2,2;2,3;2,4;2,5;2,6;" +
                                "3,2;3,3;3,4;3,5;3,6;" +
                                "4,2;4,3;4,4;4,5;4,6;" +
                                "5,2;5,3;5,4;5,5;" +
                                "6,2;6,3;6,4;6,5;" +
                                "7,2;7,3;7,4",
    num=100, filter_type=TYPE_LEAF, synthetic_nouns="nonces")
    widthdepth_tokens = dict()

    exit(1)
    for d in stats:
        num_tokens = get_num_tokens(d["full_text"])
        widthdepth = str(d["width"])+","+str(d["depth"])
        if widthdepth not in widthdepth_tokens:
            widthdepth_tokens[widthdepth] = []
        widthdepth_tokens[widthdepth].append(num_tokens)

        print(d["full_text"])
        if "idx_line" in d:
            print("-----")
            for idx, line in enumerate(d["text_lines"]):
                if idx == d["idx_line"]:
                    print("*", end="")
                else:
                    print(" ", end="")
                print("{:30s}|".format(line["cite"])+line["line_text"])
        else:
            print(d["question"])
            print(d["answer"])

        print("++++++++++")

    print("widthdepth_tokens:")
    for k, v in widthdepth_tokens.items():
        print(k, "\t", int(sum(v)/len(v)), "\t" , v)